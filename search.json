[
  {
    "objectID": "salience.html",
    "href": "salience.html",
    "title": "Model Salience Estimation",
    "section": "",
    "text": "Model salience has been used extensively in the XAI community to help interpret why models make their decisions. One of the most popular salience methods is Gradient-Weighted Class Activation Mappings (Grad-CAMs), which visulaizes the gradients of the predicted class at the final convolutional layer."
  },
  {
    "objectID": "salience.html#necessary-arguments",
    "href": "salience.html#necessary-arguments",
    "title": "Model Salience Estimation",
    "section": "Necessary Arguments",
    "text": "Necessary Arguments\n\ndevice = torch.device('cpu')"
  },
  {
    "objectID": "salience.html#loading-the-model",
    "href": "salience.html#loading-the-model",
    "title": "Model Salience Estimation",
    "section": "Loading the Model",
    "text": "Loading the Model\n\nimport torchvision.models as models\nimport torch.nn as nn\n\nFirst, load in the weights\n\nweights = torch.load(MODEL_PATH, map_location=device)\n\nNow, load weights on a single binary DesNet121 model\n\nif NETWORK == \"resnet\":\n    im_size = 224\n    model = models.resnet50(pretrained=True)\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, 2)\nelif NETWORK == \"inception\":\n    im_size = 299\n    model = models.inception_v3(pretrained=True,aux_logits=False)\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, 2)\nelif NETWORK == \"xception\":\n    im_size = 299\n    model, *_ = model_selection(modelname='xception', num_out_classes=2)\nelse: # else DenseNet\n    im_size = 224\n    model = models.densenet121(pretrained=True)\n    num_ftrs = model.classifier.in_features\n    model.classifier = nn.Linear(num_ftrs, 2)\n\n/afs/crc.nd.edu/group/TAI/Users/painswor/Explain2Me-Framework-Example/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/afs/crc.nd.edu/group/TAI/Users/painswor/Explain2Me-Framework-Example/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\ntarget_layers = [model.features[-1]]\nmodel.load_state_dict(weights['state_dict'])\nmodel = model.to(device)\nmodel.eval()\n\nDenseNet(\n  (features): Sequential(\n    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu0): ReLU(inplace=True)\n    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (denseblock1): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition1): _Transition(\n      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock2): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition2): _Transition(\n      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock3): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer17): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer18): _DenseLayer(\n        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer19): _DenseLayer(\n        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer20): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer21): _DenseLayer(\n        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer22): _DenseLayer(\n        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer23): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer24): _DenseLayer(\n        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition3): _Transition(\n      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock4): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n)"
  },
  {
    "objectID": "salience.html#preprocessing",
    "href": "salience.html#preprocessing",
    "title": "Model Salience Estimation",
    "section": "Preprocessing",
    "text": "Preprocessing\n\nimport torchvision.transforms as transforms\n\n\nif NETWORK == \"xception\":\n    # Transformation specified for the pre-processing\n    transform = transforms.Compose([\n                transforms.Resize([im_size, im_size]),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5]*3, [0.5]*3)\n            ])\nelse:\n    # Transformation specified for the pre-processing\n    transform = transforms.Compose([\n                transforms.Resize([im_size, im_size]),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n            ])\n\n\nimageScores = []\nsigmoid = nn.Sigmoid()"
  },
  {
    "objectID": "salience.html#creating-gradcam",
    "href": "salience.html#creating-gradcam",
    "title": "Model Salience Estimation",
    "section": "Creating GradCam",
    "text": "Creating GradCam\n\nfrom PIL import Image\nfrom torchcam.methods import GradCAM\nfrom torchcam.methods import GradCAMpp\nimport skimage.io\n\nLoad the image\n\n# Loading in the image\nimage = Image.open(IMAGE_PATH).convert('RGB')\n\n# Image transformation\ninput_tensor = transform(image)\n\nGenerate GradCAM\n\nif GRADCAM_TYPE == \"gradcam\":\n    #cam_extractor = GradCAM(model, target_layers)\n    cam_extractor = GradCAM(model)\nelif GRADCAM_TYPE == \"gradcamPP\":\n    cam_extractor = GradCAMpp(model, target_layers)\n\nWARNING:root:no value was provided for `target_layer`, thus set to 'features'."
  },
  {
    "objectID": "salience.html#processing-gradcam",
    "href": "salience.html#processing-gradcam",
    "title": "Model Salience Estimation",
    "section": "Processing GradCAM",
    "text": "Processing GradCAM\n\nfrom torchvision.transforms.functional import normalize, resize, to_pil_image\nfrom torchcam.utils import overlay_mask\n\nPreprocess your data and feed it to the model\n\nout = model(input_tensor.unsqueeze(0))\n\nRetrieve the CAM by passing class index and model output\n\nactivation_map = cam_extractor(out.squeeze(0).argmax().item(), out)\n\n\ncam = to_pil_image(activation_map[0].squeeze(0), mode='F')\ncam = overlay_mask(image, cam, alpha=0.50)\nif SIZE == 'upscaled':\n    cam = cam.resize((im_size, im_size), resample = Image.BICUBIC)"
  },
  {
    "objectID": "salience.html#display-gradcam",
    "href": "salience.html#display-gradcam",
    "title": "Model Salience Estimation",
    "section": "Display GradCAM",
    "text": "Display GradCAM\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\n\noriginal_image = Image.open(IMAGE_PATH).convert('RGB')\noverlayed_cam = cam\n\nfig = plt.figure(figsize=(10., 8.), facecolor='white')\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(1, 2),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 aspect=1.2\n                 )\n\nfor index, (ax, im) in enumerate(zip(grid, [original_image, overlayed_cam])):\n    # Iterating over the grid returns the Axes.\n    ax.axis('off')\n    ax.grid(None)\n    ax.imshow(im)\n    #ax.set_title(predictions[index], fontsize=45)\nfig.set_size_inches(32, 18)\nplt.show()\n\n\n\n\n\ncam.save(OUTPUT_PATH)"
  },
  {
    "objectID": "entropy.html",
    "href": "entropy.html",
    "title": "Salience Entropy",
    "section": "",
    "text": "One of the most straightforward ways of statistically summarizing the model’s salience is to study the entropy of generated salience maps. In terms of explainable-AI, well trained models typically have focused salience on the object it is classifying. High accuracy scores with unfocused salience maps may be indicators that the model has overfit the traiining data."
  },
  {
    "objectID": "entropy.html#measuring-entropy",
    "href": "entropy.html#measuring-entropy",
    "title": "Salience Entropy",
    "section": "Measuring Entropy",
    "text": "Measuring Entropy\nDefine parameters\n\nIMAGE_NAME = \"000700.png\"\nimg_path = f'../output/cams/{IMAGE_NAME}'\n\n\nCalculate Entropy\nRead in the image\n\ncam = mpimg.imread(img_path)\n\nCalculate entropy\n\nentropy = skimage.measure.shannon_entropy(cam)\n\n\n\nNormalize Entropy\nThe normalization factor Sˆpmax(m,n) plays a key role in getting accurate estimates of the entropy in case of low- and varying-resolution and quantized data (such as Grad-CAMs) and requires a commentary.\n\nnormalized_entropy = round(entropy / 5.614, 3)\nprint(normalized_entropy)\n\n1.293\n\n\n\n\nDisplay Image\n\nfig = plt.figure(figsize=(10., 8.), facecolor='white')\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(1, 1),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\nfor index, (ax, im) in enumerate(zip(grid, [cam])):\n    # Iterating over the grid returns the Axes.\n    ax.axis('off')\n    ax.grid(b=None)\n    ax.imshow(im)\n    ax.set_title(\"Normalized Entropy: \" + str(normalized_entropy), fontsize=30)\nfig.set_size_inches(18, 9)\nplt.show()\n\nValueError: keyword grid_b is not recognized; valid keywords are ['size', 'width', 'color', 'tickdir', 'pad', 'labelsize', 'labelcolor', 'zorder', 'gridOn', 'tick1On', 'tick2On', 'label1On', 'label2On', 'length', 'direction', 'left', 'bottom', 'right', 'top', 'labelleft', 'labelbottom', 'labelright', 'labeltop', 'labelrotation', 'grid_agg_filter', 'grid_alpha', 'grid_animated', 'grid_antialiased', 'grid_clip_box', 'grid_clip_on', 'grid_clip_path', 'grid_color', 'grid_dash_capstyle', 'grid_dash_joinstyle', 'grid_dashes', 'grid_data', 'grid_drawstyle', 'grid_figure', 'grid_fillstyle', 'grid_gapcolor', 'grid_gid', 'grid_in_layout', 'grid_label', 'grid_linestyle', 'grid_linewidth', 'grid_marker', 'grid_markeredgecolor', 'grid_markeredgewidth', 'grid_markerfacecolor', 'grid_markerfacecoloralt', 'grid_markersize', 'grid_markevery', 'grid_mouseover', 'grid_path_effects', 'grid_picker', 'grid_pickradius', 'grid_rasterized', 'grid_sketch_params', 'grid_snap', 'grid_solid_capstyle', 'grid_solid_joinstyle', 'grid_transform', 'grid_url', 'grid_visible', 'grid_xdata', 'grid_ydata', 'grid_zorder', 'grid_aa', 'grid_c', 'grid_ds', 'grid_ls', 'grid_lw', 'grid_mec', 'grid_mew', 'grid_mfc', 'grid_mfcalt', 'grid_ms']"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Explain2Me-Framework-Example",
    "section": "",
    "text": "This repo showcases the Explain Me This: Salience-Based Explainability for Synthetic Face Detection Models research codebase bundled with the tools and best practices developed by the frameworks group."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Explain2Me-Framework-Example",
    "section": "Getting Started",
    "text": "Getting Started\nTo use this repo, clone it and run the following commands:\npdm install\npdm run dvc repro\nDocumentation can be contributed to by editing the nbs/ files then running pdm run nbdev_prepare."
  },
  {
    "objectID": "index.html#frameworks-approach",
    "href": "index.html#frameworks-approach",
    "title": "Explain2Me-Framework-Example",
    "section": "Frameworks Approach",
    "text": "Frameworks Approach\nThe frameworks team has added the following tools for explainability and reproducability:\n\nPDM: for python package management\nDVC: for pipeline reproduceability\nnbdev: for code explainability\n\n\nDVC Pipeline and Experiments\nRather than re-creating an entire DVC Pipeleine, the frameworks team focused in on nbs/noise.ipynb to display the DVC experiments feature to allow code iterataions from the CLI or vscode plugin. To view the full configuration please view dvc.yaml.\n\nRunning Experiments\nExperiments can be run using the following methods:\nCommand Line Interface\nRun the following command with the -S argument will run the pipeline with the specified parameters.\npdm run dvc exp run -S 'noise.amount=0.01'\nVSCode Plugin (Recommended)\nThe DVC plugin for VSCode can be installed to provide an IDE for running experiments, viewing plots, and changing parameters. Check out this quick tutorial for an overview here."
  },
  {
    "objectID": "noise.html",
    "href": "noise.html",
    "title": "Salience Reaction to Image Noise",
    "section": "",
    "text": "It is reasonable to say that well-trained models should degrade their performance gracefully in presence of noise. What is proposed in this paper, and may complement the existing measures, is to compare the model’s salience maps obtained as the noise is being gradually added to the input, with the salience map calculated for clean samples."
  },
  {
    "objectID": "noise.html#necessary-arguments",
    "href": "noise.html#necessary-arguments",
    "title": "Salience Reaction to Image Noise",
    "section": "Necessary Arguments",
    "text": "Necessary Arguments\n\nMODEL_PATH = \"../models/weights/Densenet/densenet_cyborg_1/Logs/final_model.pth\"\nNETWORK = \"densenet\"\nDATASET = \"../data/images/ffhq_aligned/00001.png\"\nAMOUNT = 0.05\n\n\ndevice = torch.device('cpu')"
  },
  {
    "objectID": "noise.html#load-the-model",
    "href": "noise.html#load-the-model",
    "title": "Salience Reaction to Image Noise",
    "section": "Load The Model",
    "text": "Load The Model\nLoad weights of single binary DesNet121 model\n\nweights = torch.load(MODEL_PATH, map_location=device)\n\n\nif NETWORK == \"resnet\":\n    im_size = 224\n    model = models.resnet50(pretrained=True)\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, 2)\nelif NETWORK == \"inception\":\n    im_size = 299\n    model = models.inception_v3(pretrained=True,aux_logits=False)\n    num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(num_ftrs, 2)\nelif NETWORK == \"xception\":\n    im_size = 299\n    model, *_ = model_selection(modelname='xception', num_out_classes=2)\nelse: # else DenseNet\n    im_size = 224\n    model = models.densenet121(pretrained=True)\n    num_ftrs = model.classifier.in_features\n    model.classifier = nn.Linear(num_ftrs, 2)\n\n/afs/crc.nd.edu/group/TAI/Users/painswor/Explain2Me-Framework-Example/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/afs/crc.nd.edu/group/TAI/Users/painswor/Explain2Me-Framework-Example/.venv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\nmodel.load_state_dict(weights['state_dict'])\nmodel = model.to(device)\nmodel.eval()\n\n\nsigmoid = nn.Sigmoid()"
  },
  {
    "objectID": "noise.html#preprocessing",
    "href": "noise.html#preprocessing",
    "title": "Salience Reaction to Image Noise",
    "section": "Preprocessing",
    "text": "Preprocessing\n\nimport torchvision.transforms as transforms\n\n\nif NETWORK == \"xception\":\n    # Transformation specified for the pre-processing\n    transform = transforms.Compose([\n                transforms.Resize([im_size, im_size]),\n                transforms.ToTensor(),\n                transforms.Normalize([0.5]*3, [0.5]*3)\n            ])\nelse:\n    # Transformation specified for the pre-processing\n    transform = transforms.Compose([\n                transforms.Resize([im_size, im_size]),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n            ])"
  },
  {
    "objectID": "noise.html#get-original-prediction",
    "href": "noise.html#get-original-prediction",
    "title": "Salience Reaction to Image Noise",
    "section": "Get Original Prediction",
    "text": "Get Original Prediction\n\npredictions = []\n\nRead the image\n\nimage = skimage.io.imread(DATASET)\nimage = Image.fromarray(image)\nimage\n\n\n\n\nModel Preprocessing\n\ntranformImage = transform(image)\ntranformImage = tranformImage[0:3,:,:].unsqueeze(0)\ntranformImage = tranformImage.to(device)\n\nGet Prediction from Model\n\nwith torch.no_grad():\n    output = model(tranformImage)\n\n\nPAScore = round(sigmoid(output).detach().cpu().numpy()[:, 1][0], 3)\npredictions.append(PAScore)\nprint(PAScore)\n\n0.781"
  },
  {
    "objectID": "noise.html#getting-prediction-of-noisy-image",
    "href": "noise.html#getting-prediction-of-noisy-image",
    "title": "Salience Reaction to Image Noise",
    "section": "Getting Prediction of Noisy Image",
    "text": "Getting Prediction of Noisy Image\n\nimport numpy as np\n\nRead the Image\n\nimage_np = skimage.io.imread(DATASET)\n\nGenerate Random Noise\n\nsalt_pepper = skimage.util.random_noise(image_np, mode='s&p', amount=AMOUNT)\nsalt_pepper = np.array((salt_pepper * 255).astype(np.uint8))\nsalt_pepper = Image.fromarray(salt_pepper)\n\nModel Preprocessing\n\ntranformImage = transform(salt_pepper)\ntranformImage = tranformImage[0:3,:,:].unsqueeze(0)\ntranformImage = tranformImage.to(device)\n\nGet Prediction From Model\n\nwith torch.no_grad():\n    output = model(tranformImage)\n\n\nPAScore = round(sigmoid(output).detach().cpu().numpy()[:, 1][0], 3)\npredictions.append(PAScore)\nprint(PAScore)\n\n0.008"
  },
  {
    "objectID": "noise.html#display-both-images",
    "href": "noise.html#display-both-images",
    "title": "Salience Reaction to Image Noise",
    "section": "Display Both Images",
    "text": "Display Both Images\n\nfig = plt.figure(figsize=(10., 8.), facecolor='white')\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(1, 2),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\nfor index, (ax, im) in enumerate(zip(grid, [image, salt_pepper])):\n    # Iterating over the grid returns the Axes.\n    ax.axis('off')\n    ax.imshow(im)\n    ax.set_title(predictions[index], fontsize=45)\nfig.set_size_inches(32, 18)\n#plt.savefig(\"noise-densenet-example.png\", format='png', bbox_inches='tight', dpi = 500)\nplt.show()"
  },
  {
    "objectID": "noise.html#save-results",
    "href": "noise.html#save-results",
    "title": "Salience Reaction to Image Noise",
    "section": "Save Results",
    "text": "Save Results\n\nSave PAScores to JSON\nInitialize save location with DVCLive\n\nlive = Live(dir=\"../eval\", dvcyaml=False, report=None)\n\nSave metrics\n\nmetrics = {\n    \"pascore\" : str(predictions[1]),\n}\nlive.summary = metrics\nlive.make_summary()\n\nSave Images\n\nlive.log_image(\"noise.png\", salt_pepper)"
  },
  {
    "objectID": "noise.html#creating-gradcam",
    "href": "noise.html#creating-gradcam",
    "title": "Salience Reaction to Image Noise",
    "section": "Creating GradCAM",
    "text": "Creating GradCAM\nTransform the Images\n\nimage_tensor = transform(salt_pepper)\n\nCreating the Grad-Cam\n\ncam_extractor = GradCAM(model)\n\nWARNING:root:no value was provided for `target_layer`, thus set to 'features'."
  },
  {
    "objectID": "noise.html#processing-gradcam",
    "href": "noise.html#processing-gradcam",
    "title": "Salience Reaction to Image Noise",
    "section": "Processing GradCAM",
    "text": "Processing GradCAM\nPreprocess your data and feed it to the model\n\nout = model(image_tensor.unsqueeze(0))\nactivation_map = cam_extractor(out.squeeze(0).argmax().item(), out)\n\nRetrieve the CAM by passing the class index and the model output\n\ncam = to_pil_image(activation_map[0].squeeze(0), mode='F')\n\n\ncam = overlay_mask(salt_pepper, to_pil_image(activation_map[0].squeeze(0), mode='F'), alpha=0.50)\n\n\ncam = cam.resize((im_size, im_size), resample = Image.BICUBIC)"
  },
  {
    "objectID": "noise.html#displaying-gradcam",
    "href": "noise.html#displaying-gradcam",
    "title": "Salience Reaction to Image Noise",
    "section": "Displaying GradCAM",
    "text": "Displaying GradCAM\n\nfig = plt.figure(figsize=(10., 8.), facecolor='white')\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(1, 2),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 aspect=1.2\n                 )\n\nfor index, (ax, im) in enumerate(zip(grid, [salt_pepper, cam])):\n    ax.axis('off')\n    ax.imshow(im)\n    #ax.set_title(predictions[index], fontsize=45)\nfig.set_size_inches(32, 18)\n#plt.savefig(\"entropy-densenet-example.png\", format='png', bbox_inches='tight', dpi = 500)\nfig.set_size_inches(32, 18)\nplt.show()\n\n\n\n\n\nlive.log_image(\"cam.png\", cam)\n\nNameError: name 'live' is not defined"
  }
]